  老师 这周我学习了一下抄袭检测研究这本书，我当综述来读，实验部分没有深入理解，出书的时间会前一点，方法不一定是最新的，但是思想是可以去学习的
书中描述，目前抄袭检测研究有三方面挑战：①抄袭语料匮乏，②高模糊抄袭检索方法 还停留在，基于启发式源检索方法上，基于启发式源检索方法很大程度上基于专家经验调参，具有定制性和随机性；③高模糊抄袭检测文本对齐性能有待提升；

抄袭检索任务主要包括了：①语料构建；②抄袭源检索③抄袭文本对齐；
PAN于12年加入CLEF，向参赛者发测试和训练数据，并根据标准答案进行评价
抄袭语料 尤其是高质量的抄袭语料难构建，主要是因为抄袭是隐蔽的，抄袭者会受到法律、道德方面问题，会用尽手段使其不易识别，所以抄袭文本显示识别比较困难，也不易获得抄袭者本人同一做研究；

  抄袭源检索任务：一篇可疑的文档，做查询生成，把关键词（主题词）提取出来，交给搜索引擎做检索，然后再做检索过滤
  查询生成现有主要基于启发式的方法是：①使用文档上的高频词查询；
②具有高TFIDF的词查询 3 命名实体查询 4文档级稀有词做查询 5仅使用名词动词形容词做查询

释义文本匹配：释义抄袭释义抄袭检测研究本质上是语义匹配，涉及词义理解和文本相似度计算等问题，不考虑语义的方法通常识别文本相似的方法，就是我们早期做的实验 文本向量化表示，文本相似度计算，这种方法的抄袭检测性能不是太令人满意，语言离散表达，很多同义词 例如 抄袭 剽窃二词即使同一，但是也被看成两个不同的词，基于离散语言模型的方法无法处理‘一词多义’和‘一义多词’；书中提到 可以通过句法特征助力释义判别性能提升，通过分析得到的句子结构和结构所具有的的句法特征，结合语义判断可以提升释义判别性能，实践中可以用斯坦福的句法分析工具来用。

文本抄袭算是文本复用抄袭里的特殊领域，文本复用是很常见的，像新闻媒体传播新闻，多家新闻平台针对同一则信息，都会用自己的描述去报道，
文本复用的方式有思想、释义、词复用等

根据抄袭程度不同，可以分为低模糊抄袭以及高模糊抄袭，
低模糊抄袭完全copy，部分copy，简单修改，
高模糊抄袭可分为：翻译抄袭、观点抄袭，


外部抄袭检测 就是之前提到的源检索和文本对齐 从多篇文档来判断是否有抄袭可能，内部抄袭检测 是仅依靠可疑文档本身来判断是否存在抄袭，比如 基于作者写作风格变换来识别抄袭

源检索过程框架：（1）分块（chunking）：给出一篇可疑文档dg，分块将文本划分为更小的片段或块。
（2）关键词提取（keyphrase extraction）：从给定的可疑文本片段中提取关键词，这些关键词将用于构建查询，检索抄袭源。
（3）查询构造（query formulation）：提取出的关键词，将它表示为搜索引擎支持的查询格式。
（4）搜索控制（search control）：给出一个查询的集合，分配   /  查询提交给搜索引擎的顺序   /  然后下载搜索的结果。
（5）下载过滤（download filtering）：应用一个过滤算法 / 从下载的文档里 /  过滤掉不值得进一步与可疑文档比对的文档。

文本对齐：①给出一个可疑文档和一个源文档，抄袭文本匹配  就是找到两个文档的匹配部分，这个匹配部分也称为抄袭种子；
②抄袭片段对齐。对于识别出的可疑文档和抄袭源文档中的匹配的抄袭片段，将其合并为具有最大长度的对齐文本片段。


内部抄袭检测框架：①片段拆分。首先将可疑文档dog拆分成小的文本片段，比如章节、段落、句子甚至词。
②文体（stylometry）特征提取。从不同的片段中提取文体学特征（stylometric）。
③文体学特征量化和分析。使用  / 基于文体学的度量方法和质量函数 /  来分析文本不同风格特征的变化。


跨语言抄袭检测一般含有两条路径，第一种可疑文本经过机器翻译后 同单语言检测一致，对其做查询提取获得其源文档，这里的指纹指的是可疑文档经机器翻译后的文本；第二种是直接做查询提取，然后应用跨语言信息检索方法获得抄袭源文档。
跨语言检测也受限于：机器翻译性能，翻译的歧义；跨语言翻译文本 词的次序判断会乱，词句法结构分析判断不是那么重要；大多数方法都离不开机器翻译，没有充分利用双语文本其他特征。


第三章
①指纹生成算法：用指纹表示语言，通过某种选取策略从文档中选取称为‘指纹’的字符串；用哈希函数将指纹映射为一个数字，不通指纹代表了不同文本内容，比较可疑文档与源文档指纹来决策两篇文档相似程度，此法是早期超限检测研究的重点
②基于词袋模型的抄袭检测：将可以文档拆分为块，用词袋模型表示块，用词频统计方法统计两个文档中共有的字符或单词书，以此来判断块的相似性来获得抄袭源；结合去处停用词和重复词，去对比；
③基于TFIDF模型的抄袭检测方法：用TFIDF模型将可疑文档与原文档表示为由此项组成的向量空间下向量，然后通过计算向量相似度度量文本相似性；书中使用TFIDF模型，是应用余弦距离结合杰卡德系数；
④基于N*gram模型的抄袭检测方法，实验二；
⑤句法：用词性序列表示文本，此法用词性标注工具获得文本的词性，然后利用词性序列的相似检测抄袭，这个方法是基于释义抄袭中词可能被抄袭者更换，抄袭文本的词性序列与源文本相似的特征检测抄袭
⑥基于连续语言表示的抄袭检测算法：通过对语义的理解来计算文本的相似度，目前这方面的研究还比较少，第三章综述，目前的研究还停留在基于离散语言表示阶段。

第四章：
现有抄袭语料构建，自动生成的语料要么是简单照搬照抄，自动生成的语料不具有实际意义，人工制作的语料更接近真实的抄袭，但人工生成语料 成本高、耗时长；
11年孙教授提出一种思想  是将互联网上用户出于各种交际目的而“制作”出来的资源用于自然语言处理。这些资源，是用户无意识情况下为自然语言处理研究所需的各种资源做出的义务“标注”。
通过这个思想的启发，书中提出一种基于自然标注的抄袭语料构建，想法是：人为了躲避抄袭检测，往往会认真使用释义方法修改文档，保证修改后文本可读性和语义，我对于这个方法的解读是，就像普通本科学生做毕设时，会参考一些前人的想法 写出初稿，把论文初稿交给查重平台，第一次查询，生成查询检测报告，重复率可能会比较高，然后学生根据查询检测报告，用各种手段修改同义词，再保证文章可读性和整体逻辑的情况下去降重，经过降重后，将会生成具有更高模糊度的抄袭语料。随后文章提出了获取抄袭案例文本对其算法，以及通过第三方评价，证明此法的有效性。

本书后面章节的实验部分，没太看懂，没法再汇报加入，汇报就到这里






